{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ASPECT BASED SENTIMENT ANALYSIS\n",
        "\n",
        "###Python script that demonstrates the analysis of sentiments by aspects using the NLTK library for analysis and pandas for data manipulation\n",
        "\n"
      ],
      "metadata": {
        "id": "s2lkWBM9On2T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbOrpoP11dlE"
      },
      "outputs": [],
      "source": [
        "#Importing necessary packages and libraries\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "#Downloading nltk vader lexicon\n",
        "nltk.download('vader_lexicon')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####PREPROCESSING"
      ],
      "metadata": {
        "id": "s06YdEnjPhHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    #Converting text to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    #Removing URLs\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text, flags=re.MULTILINE)\n",
        "    \n",
        "    #Removing punctuation\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "    \n",
        "    #Tokenizing\n",
        "    tokens = word_tokenize(text)\n",
        "    \n",
        "    #Removing stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    \n",
        "    #Lemmatizing the tokens\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    \n",
        "    #joining the tokens \n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    \n",
        "    return preprocessed_text\n"
      ],
      "metadata": {
        "id": "dnb7ktts1_8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reading .csv file\n",
        "df = pd.read_csv('DATA FILE NAME')"
      ],
      "metadata": {
        "id": "pwSxqBXt9Hkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Looking into data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "sscA7lZt_xqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying preprocessing function\n",
        "df['clean_text'] = df['review-en'].apply(preprocess_text)\n"
      ],
      "metadata": {
        "id": "rFmkdcXf2EcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment Intensity Analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "#Sentiment analysis on reviews\n",
        "df['sentiment_score'] = df['clean_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
        "\n",
        "#Mapping sentiment scores (not necessary)\n",
        "score_sentiment_mapping = {\n",
        "    1: 'Very Negative',\n",
        "    2: 'Negative',\n",
        "    3: 'Neutral',\n",
        "    4: 'Positive',\n",
        "    5: 'Very Positive'\n",
        "}\n",
        "\n",
        "df['sentiment_label'] = df['sentiment_score'].map(score_sentiment_mapping)\n"
      ],
      "metadata": {
        "id": "_T6tIsZpRFSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining aspects and corresponding keywords\n",
        "aspects = {\n",
        "    'Application': ['application', 'registration', 'account', 'lagging', 'features', 'support', 'update', 'improvement'],\n",
        "    'Price': ['price','cost','expensive','affordable','fee','money','payment','prices','payments', 'cheap'],\n",
        "    'Tutors': ['tutor', 'tutoring', 'teacher', 'helpful', 'knowledgeable','solution','answer','instructor','mentor','performance','attention','correct','wrong', 'response', 'accuracy','accurate','clear'],\n",
        "    'Helpfullness': ['helpfulness','assistance','helpful', 'quality', 'exam', 'reliable', 'coach','assistance']\n",
        "}\n",
        "\n",
        "aspect_sentiments = {}  #dict to store sentiment scores \n",
        "\n",
        "#Calculating average sentiment scores \n",
        "for aspect, keywords in aspects.items():\n",
        "    aspect_df = df[df['clean_text'].str.contains('|'.join(keywords), case=False)]\n",
        "    average_sentiment = aspect_df['sentiment_score'].mean()\n",
        "    aspect_sentiments[aspect] = average_sentiment\n",
        "\n",
        "#Creating df from the aspect sentiments\n",
        "aspect_sentiment_df = pd.DataFrame.from_dict(aspect_sentiments, orient='index', columns=['Average Sentiment Score'])\n",
        "aspect_sentiment_df.index.name = 'Aspect'\n",
        "\n",
        "print(aspect_sentiment_df)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s4b-32vV5ip",
        "outputId": "e2bea230-e95e-43b2-a883-13ddb25bce36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Average Sentiment Score\n",
            "Aspect                               \n",
            "Application                  0.405978\n",
            "Price                        0.290372\n",
            "Tutors                       0.317885\n",
            "Helpfullness                 0.381162\n"
          ]
        }
      ]
    }
  ]
}